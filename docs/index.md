# Udacity Deep Learning Nanodegree Foundation
(11.2017 - 04.2018)

## About
This Udacity Nanodegree Foundation is taught by several specialists on Deep Learning and takes you from Neuronal Networks over Convolutional and Recurrent Networks to Reinforcement Learning. It offers a lot of practice and exposure to many projects and tools.

## Course Work
Here you can find the projects and exercises we did in the course. The **projects** were independent work, whereas the **exercises** came with a solution that you would help you in case you got stuck.

### Part 1: Introduction


### Part 2: Neuronal Networks


### Part 3: Convolutional Networks
- Project2: Dog breed recognising app build with a pretrained CNN In this project we used pretrained CNNs to build an app that could distinguish dogs and humans and predict the breed for dogs.

### Part 4: Recurrent Networks
- **Project**: [an RNN trained on TV scripts of the Simpsons](dlnd_tv_script_generation.html)
- Exercise


### Part 5: Generative Adverserial Networks
GANs are Generative Adverserial Networks. In these networks two players: a discriminator and a generator are trained in parallel with opposite goals: the generator wants to produce fakes, that go through as real and the discrimnator wants to detect fakes and reject them. The overall goal is to improve both player, where the focus might be on either of them.

### Part 5: Reinforcement Learning
(not yet done)


## Convolutional Networks
## Project2: Dog breed recognising app build with a pretrained CNN
In this project we used pretrained CNNs to build an app that could distinguish dogs and humans and predict the breed for dogs.
[Link to the project repo](https://github.com/sabinem/udacity-deeplearning-dog-project)

## Recurrent Networks
## Project3: Generate a TV script with an RNN
In this projects an RNN predicted the next word. It was trained on TV scripts of the Simpsons.
It uses LSTMs
[Link to the project directory](RNNs/tv_script_rnn)

## Generative Adversarial Networks
- [Link to the project directory](GANs/gan_mnist)

### GANs with MNIST
GANs are Generative Adverserial Networks. In these networks two players: a discriminator and a generator are trained in parallel with opposite goals: the generator wants to produce fakes, that go through as real and the discrimnator wants to detect fakes and reject them. The overall goal is to improve both player, where the focus might be on either of them.

## Exercise 1: MNIST with a GAN
In this exercise a Gan was build to create fake handwritten digits:
- this is a small project, that does not take much time to train and you can none the less watch how a GAN works and trains
[Link to the project directory](GANs/gan_mnist)

### Batchnormalization
batch normalization can make NN training a lot more robust for deep networks
- lesson that compares training with and without batch normalization: [html](Batch_Normalization_Lesson.html) / [notebook](https://github.com/sabinem/udacity_DL/blob/master/batch_normalization/README.md)

## Deep Reinforcement Learning

This repo summarizes what I have learned in the Udacity Deep Learning Nanodegree. The index includes links to the many exercises and projects that were part of this program.
